---
title: "Human Activity Recognition"
author: "Ricardo Jorge Gil Ramos"
date: "02/22/2015"
output: html_document
---
#Executive Summary
The goal of this work is to predict human activities by collected data using devices such as Jawbone Up, Nike FuelBand, and Fitbit. The approach of research is based upon this paper http://groupware.les.inf.puc-rio.br/har.

The 5 possible methods include:

    A: exactly according to the specification
    B: throwing the elbows to the front
    C: lifting the dumbbell only halfway
    D: lowering the dumbbell only halfway
    E: throwing the hips to the front

The main objectives of this project are as follows

    Predict the manner in which they did the exercise depicted by the classe variable.
    Build a prediction model using different features and cross-validation technique.
    Calculate the out of sample error.
    Use the prediction model to predict 20 different test cases provided. 

#Analysis
The data for this project come from this source: http://groupware.les.inf.puc-rio.br/har

```r
setwd('/home/user/machine_learning')
training_data <- read.csv(file="pml-training.csv", na.strings=c("", "NA"), header=TRUE, stringsAsFactors = FALSE)
testing_data <- read.csv(file="pml-testing.csv", , na.strings=c("", "NA"), header=TRUE, stringsAsFactors = FALSE)

# Create training classe as a factor
training_data$classe <- as.factor(training_data$classe) 
```
We remove features that contains missing values in this way:

```r
# Cleaning training and testing data
training_data_num_NA <- apply(training_data, 2, function(x) {sum(is.na(x))}) 
training_data_cleaned <- training_data[,which(training_data_num_NA==0)]
training_data_cleaned$classe <- as.factor(training_data_cleaned$classe) 

testing_data_num_NA <- apply(testing_data, 2, function(x) {sum(is.na(x))}) 
testing_data_cleaned <- testing_data[,which(testing_data_num_NA==0)]

```

#Preprocessing variables
```r
library(caret)
numeric_cols <- which(lapply(training_data_cleaned, class) %in% "numeric")

preObj <-preProcess(training_data_cleaned[,numeric_cols], method=c('knnImpute', 'center', 'scale'))
trainLess1 <- predict(preObj, training_data_cleaned[, numeric_cols])
trainLess1$classe <- training_data_cleaned$classe

testLess1 <-predict(preObj, testing_data_cleaned[, numeric_cols])
```

We use the function nearZeroVar in caret library to filter predictors that only have one unique value, or have few unique values relative to the number of samples and the ratio of frequency of the most common value to the frequency of second most common value is large.

```r
nzv <- nearZeroVar(trainLess1, saveMetrics=TRUE)
training_data_final <- trainLess1[,nzv$nzv==FALSE]

nzv <- nearZeroVar(testLess1, saveMetrics=TRUE)
testing_data_final <- testLess1[,nzv$nzv==FALSE]
```
The final set of predictors used for classification are as follows.

```r
names(training_data_final)
```
#Create cross validation set

We divide the whole set in two parts, we split 70% of observations for training and the 30% remaining for crossvalidation.

```r
set.seed(20150222)

inTrain <- createDataPartition(training_data_final$classe, p = 0.70, list=FALSE)
training <- training_data_final[inTrain,]
testing <- training_data_final[-inTrain,]
```
#Model and Prediction


Now, using the features in the training dataset, we will build our model using the Random Forest machine learning technique.

```r
library(randomForest)
predictor <- randomForest(classe ~ ., data = training)
```

```{r, echo=FALSE}
setwd('/home/user/machine_learning')
training_data <- read.csv(file="pml-training.csv", na.strings=c("", "NA"), header=TRUE, stringsAsFactors = FALSE)
testing_data <- read.csv(file="pml-testing.csv", , na.strings=c("", "NA"), header=TRUE, stringsAsFactors = FALSE)

# Create training classe as a factor
training_data$classe <- as.factor(training_data$classe) 

# Cleaning training and testing data
training_data_num_NA <- apply(training_data, 2, function(x) {sum(is.na(x))}) 
training_data_cleaned <- training_data[,which(training_data_num_NA==0)]
training_data_cleaned$classe <- as.factor(training_data_cleaned$classe) 

testing_data_num_NA <- apply(testing_data, 2, function(x) {sum(is.na(x))}) 
testing_data_cleaned <- testing_data[,which(testing_data_num_NA==0)]

library(caret)
numeric_cols <- which(lapply(training_data_cleaned, class) %in% "numeric")

preObj <-preProcess(training_data_cleaned[,numeric_cols], method=c('knnImpute', 'center', 'scale'))
trainLess1 <- predict(preObj, training_data_cleaned[, numeric_cols])
trainLess1$classe <- training_data_cleaned$classe

testLess1 <-predict(preObj, testing_data_cleaned[, numeric_cols])

nzv <- nearZeroVar(trainLess1, saveMetrics=TRUE)
training_data_final <- trainLess1[,nzv$nzv==FALSE]

nzv <- nearZeroVar(testLess1, saveMetrics=TRUE)
testing_data_final <- testLess1[,nzv$nzv==FALSE]

set.seed(20150222)

inTrain <- createDataPartition(training_data_final$classe, p = 0.70, list=FALSE)
training <- training_data_final[inTrain,]
testing <- training_data_final[-inTrain,]

library(randomForest)
predictor <- randomForest(classe ~ ., data = training)
predictor
```

#In sample accuracy

Here, we calculate the in sample accuracy which is the prediction accuracy of our model on the training data set.

```r
training_predictor = predict(predictor, newdata = training)
accuracy_training = confusionMatrix(training$classe, training_predictor)$overall[1]
```
```{r, echo=FALSE}
training_predictor = predict(predictor, newdata = training)
accuracy_training = confusionMatrix(training$classe, training_predictor)$overall[1]
confusionMatrix(training$classe, training_predictor)$overall
```

#Out sample accuracy


We calculate the out of sample accuracy of the model. In other words, this describes how accurately the model performs on the 30% testing dataset

```r
testing_predictor = predict(predictor, newdata = testing)
accuracy_testing = confusionMatrix(testing$classe, testing_predictor)$overall[1]
```
```{r, echo=FALSE}
testing_predictor = predict(predictor, newdata = testing)
accuracy_testing = confusionMatrix(testing$classe, testing_predictor)$overall[1]
confusionMatrix(testing$classe, testing_predictor)
```
It can be concluded that the algorithm's accuracy is equal to 99.59% and the out of sample error is 0.41%.

#Prediction Assignment

Here, we apply the machine learning algorithm we built above, to each of the 20 test cases in the testing data set provided.

```r
answers <- predict(predictor, testing_data_cleaned)
answers <- as.character(answers)
answers
```
```{r, echo=FALSE}
answers <- predict(predictor, testing_data_cleaned)
answers <- as.character(answers)
answers
```

Finally, we write the answers to files as specified by the course instructor using the following code segment.
```r
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

pml_write_files(answers)
```