---
title: "Human Activity Recognition"
author: "Ricardo Jorge Gil Ramos"
date: "02/22/2015"
output: html_document
---
#Executive Summary
The goal of this work is to predict human activities by collected data using devices such as Jawbone Up, Nike FuelBand, and Fitbit. The approach of research is based upon this paper http://groupware.les.inf.puc-rio.br/har.

The 5 possible methods include:

    A: exactly according to the specification
    B: throwing the elbows to the front
    C: lifting the dumbbell only halfway
    D: lowering the dumbbell only halfway
    E: throwing the hips to the front

The main objectives of this project are as follows

    Predict the manner in which they did the exercise depicted by the classe variable.
    Build a prediction model using different features and cross-validation technique.
    Calculate the out of sample error.
    Use the prediction model to predict 20 different test cases provided. 

#Analysis
The data for this project come from this source: http://groupware.les.inf.puc-rio.br/har

```r
setwd('/home/user/machine_learning')
training_data <- read.csv(file="pml-training.csv", na.strings=c("", "NA"), header=TRUE, stringsAsFactors = FALSE)
testing_data <- read.csv(file="pml-testing.csv", , na.strings=c("", "NA"), header=TRUE, stringsAsFactors = FALSE)

# Create training classe as a factor
training_data$classe <- as.factor(training_data$classe) 
```
As we *belt*, *forearm*, *arm*, and *dumbell* of 6 participants
We remove features that contains missing values in this way:

```r
# Cleaning training and testing data
training_data_num_NA <- apply(training_data, 2, function(x) {sum(is.na(x))}) 
training_data_cleaned <- training_data[,which(training_data_num_NA==0)]
training_data_cleaned$classe <- as.factor(training_data_cleaned$classe) 

testing_data_num_NA <- apply(testing_data, 2, function(x) {sum(is.na(x))}) 
testing_data_cleaned <- testing_data[,which(testing_data_num_NA==0)]

```

#Preprocessing variables

numeric_cols <- which(lapply(training_data_cleaned, class) %in% "numeric")

preObj <-preProcess(training_data_cleaned[,numeric_cols], method=c('knnImpute', 'center', 'scale'))
trainLess1 <- predict(preObj, training_data_cleaned[, numeric_cols])
trainLess1$classe <- training_data_cleaned$classe

testLess1 <-predict(preObj, testing_data_cleaned[, numeric_cols])


We use the function nearZeroVar in caret library to filter predictors that only have one unique value, or have few unique values relative to the number of samples and the ratio of frequency of the most common value to the frequency of second most common value is large.

```r
library(caret)
nzv <- nearZeroVar(trainLess1, saveMetrics=TRUE)
training_data_final <- trainLess1[,nzv$nzv==FALSE]

nzv <- nearZeroVar(testLess1, saveMetrics=TRUE)
testing_data_final <- testLess1[,nzv$nzv==FALSE]
```
The final set of predictors used for classification are as follows.

```r
names(training_data_final)
```
#Create cross validation set

We divide the whole set in two parts, we split 70% of observations for training and the 30% remaining for crossvalidation.

```r
set.seed(20150222)

inTrain <- createDataPartition(training_data_final$classe, p = 0.70, list=FALSE)
training <- training_data_final[inTrain,]
testing <- training_data_final[-inTrain,]
```
#Model and Prediction


Now, using the features in the training dataset, we will build our model using the Random Forest machine learning technique.

```r
library(randomForest)
predictor <- randomForest(classe ~ ., data = training)
```

#Out sample accuracy

Here, we calculate the in sample accuracy which is the prediction accuracy of our model on the training data set.

```r
testPred = predict(predictor, newdata = testing)
accuracy = confusionMatrix(testing$classe, testPred)$overall[1]
```
It can be concluded that the algorithm's accuracy is equal to 99.40% and the out of sample error is 0.60%.
